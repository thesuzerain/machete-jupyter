{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880a8c78",
   "metadata": {},
   "source": [
    "\n",
    "# Tagging - Dictionary learning\n",
    "\n",
    "Our first attempt, creating tags by naive clustering, was not successful.\n",
    "\n",
    "We need to use a strategy that:\n",
    "\n",
    "- can cluster an arbitrary number of word vectors\n",
    "- allows *multiple* tags per sentence fragment\n",
    "\n",
    "We look into using a decomposition method, which reduces all vectors to a set of common factors that allow it to be rebuilt (as linear combinations of these factors) while losing as little information as possible.\n",
    "\n",
    "In particular, we can use dictionary learning, which has a similar use case anyway. With our extracted common factors (which are vectors that 'make up' our words), we can round it to the nearest word vector. This word vector/word could be considered to be a key component in reconstituting (and as thus, a key contextual component).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e63f7-9e32-48e5-9844-5c0fc3433e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import cluster\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "\n",
    "import spacy # if this gives an error, downgrade to python 3.12.3\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d7e6f-477e-48b1-9ac3-fa316a9edea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word vectors from a list of noun chunks\n",
    "# Returns a dictionary mapping words to their index in the matrix, and the matrix itself\n",
    "def extract_vectors(noun_chunks):\n",
    "    word_vectors = {}\n",
    "    # set as upper bounds (assuming no duplicates)\n",
    "    word_vector_matrix = np.zeros(shape=(len(noun_chunks), 300))\n",
    "\n",
    "    #TODO: rewrite to be pythonic\n",
    "    i = 0\n",
    "    for word in noun_chunks:\n",
    "        if word.text in word_vectors:\n",
    "            continue\n",
    "        word_vector_matrix[i,:] = word.vector\n",
    "        word_vectors[word.text] = i\n",
    "        i = i + 1\n",
    "\n",
    "    word_vector_matrix = word_vector_matrix[:i,:]\n",
    "    \n",
    "    return word_vectors, word_vector_matrix\n",
    "\n",
    "\n",
    "# Load sample words\n",
    "sample_words = pd.read_json(\"res/example_word_list.json\")[0].to_list()\n",
    "sample_words = [nlp(x).noun_chunks for x in sample_words]\n",
    "sample_words = [x for xs in sample_words for x in xs]\n",
    "\n",
    "# Extract word vectors from words\n",
    "wv_mapping, wv_matrix = extract_vectors(sample_words)\n",
    "reverse_wv_mapping = {v: k for k, v in wv_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c4422dc5-6c35-43ab-8536-a3d0b01d0303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Red (alternates: ['Boac', 'Blue', '-Blue', 'BlazBlue'])\n",
      "Topic 1: Halberd (alternates: ['halberd', 'Halbe', 'Halberstram', 'Halberstam'])\n",
      "Topic 2: night (alternates: ['nightime', \"G'night\", '/night', 'night-'])\n",
      "Topic 3: Storm (alternates: ['giant', 'PhpStorm', 'WildStorm', 'Giant'])\n",
      "Topic 4: bolt (alternates: ['bolts', 'Skybolt', 'Trebolt', 'unbolt'])\n",
      "Topic 5: Fire (alternates: ['-Fire', 'FireRed', 'FireFly', 'Firey'])\n",
      "Topic 6: Gold (alternates: ['Silver', 'Atragon', 'SoulSilver', 'Moondragon'])\n",
      "Topic 7: EnOcean (alternates: ['Ocean', 'Oceanus', 'Oceans', 'Piscean'])\n",
      "Topic 8: sword (alternates: ['swords', 'swordtail', 'Elsword', 'dagger'])\n",
      "Topic 9: axe (alternates: ['ax', 'scythe', 'Giant', 'sledgehammer'])\n",
      "Topic 10: arch (alternates: ['arches', 'arching', 'arched', 'archways'])\n",
      "Topic 11: Cloud (alternates: ['giant', 'pCloud', 'cloud', 'ownCloud'])\n",
      "Topic 12: Sword (alternates: ['Swords', 'Swordplay', 'Swordsman', 'Longsword'])\n",
      "Topic 13: Moon (alternates: ['McMoon', 'giant', 'Moonglow', 'Moondragon'])\n",
      "Topic 14: Dark (alternates: ['Darkrai', 'Darkmoon', 'Moondragon', 'Darkon'])\n",
      "Topic 15: Parectopa (alternates: ['FUAM', 'Anvita', 'donaghy', 'Neligh'])\n",
      "Topic 16: Black (alternates: ['-Black', 'Black-', 'Black/', 'Blacky'])\n",
      "Topic 17: Fireball (alternates: ['Fireballs', 'Spaceball', 'Pokeball', 'Cueball'])\n",
      "Topic 18: dragon (alternates: ['Moondragon', 'Eragon', 'Atragon', 'dragons'])\n",
      "Topic 19: Orange (alternates: ['-Orange', 'Orangevale', \"L'Orange\", 'Orangery'])\n"
     ]
    }
   ],
   "source": [
    "# Attempt latent dirichlet allocation\n",
    "num_components = 20\n",
    "# num_components = None\n",
    "\n",
    "model = DictionaryLearning(n_components=num_components, alpha=10, random_state=42, transform_algorithm='threshold')\n",
    "model = model.fit(wv_matrix)\n",
    "\n",
    "key_words_rounded = []\n",
    "key_words_rounded_vectors = np.zeros(shape=(num_components, 300))\n",
    "for i in range(num_components):\n",
    "    key_word_vector = model.components_[i]\n",
    "    key_word_vector = nlp.vocab.vectors.most_similar(key_word_vector.reshape(1,-1), n=5)[0][0]\n",
    "    key_words = [nlp.vocab.strings[x] for x in key_word_vector]\n",
    "\n",
    "    # Key word is rounded to the nearest word in the vocabulary\n",
    "    key_words_rounded.append(key_words[0])\n",
    "    key_words_rounded_vectors[i,:] = key_word_vector[0]\n",
    "\n",
    "    # Print out the key words for the topics, as well as close alternatives\n",
    "    print(f\"Topic {i}: {key_words[0]} (alternates: {key_words[1:]})\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "685d503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 'Red': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Shadow dragon', 'Dark dragon', 'Black ogre', 'Red ogre', 'Blue ogre', 'Moon giant', 'Sword']\n",
      "Topic 'Halberd': ['Sword']\n",
      "Topic 'night': ['night']\n",
      "Topic 'Storm': ['Red dragon', 'Blue dragon', 'Shadow dragon', 'Dark dragon', 'Red ogre', 'Storm giant', 'Cloud giant', 'Moon giant', 'Sword', 'Giant axe']\n",
      "Topic 'bolt': ['lightning', 'Lightning bolt']\n",
      "Topic 'Fire': ['Red dragon', 'Red ogre', 'Water yai', 'Fire yai', 'Sword']\n",
      "Topic 'Gold': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Red ogre', 'Blue ogre', 'Moon giant', 'Flaming sword', 'Sword', 'Giant axe']\n",
      "Topic 'EnOcean': ['Blue dragon', 'Dark dragon', 'Moon giant', 'Ocean devil']\n",
      "Topic 'sword': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Flaming sword', 'Sword', 'night', 'Rusting sword', 'Molten sword', 'lightning', 'Giant axe', 'Flaming arch', 'Lightning bolt']\n",
      "Topic 'axe': ['Red dragon', 'Shadow dragon', 'Dark dragon', 'Red ogre', 'Storm giant', 'Moon giant', 'Flaming sword', 'Sword', 'Rusting sword', 'Molten sword', 'Giant axe']\n",
      "Topic 'arch': ['Red dragon', 'Flaming sword', 'night', 'Rusting sword', 'lightning', 'Flaming arch']\n",
      "Topic 'Cloud': ['Red dragon', 'Blue dragon', 'Dark dragon', 'Storm giant', 'Cloud giant', 'Moon giant']\n",
      "Topic 'Sword': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Shadow dragon', 'Dark dragon', 'Red ogre', 'Flaming sword', 'Sword', 'Rusting sword', 'Molten sword', 'Giant axe']\n",
      "Topic 'Moon': ['Red dragon', 'Blue dragon', 'Shadow dragon', 'Dark dragon', 'Red ogre', 'Storm giant', 'Cloud giant', 'Moon giant', 'Sword']\n",
      "Topic 'Dark': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Black ogre', 'Red ogre', 'Blue ogre', 'Storm giant', 'Moon giant', 'Flaming sword', 'Sword', 'Molten sword']\n",
      "Topic 'Parectopa': []\n",
      "Topic 'Black': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Shadow dragon', 'Dark dragon', 'Black ogre', 'Red ogre', 'Blue ogre', 'Sword']\n",
      "Topic 'Fireball': ['Red dragon', 'Blue dragon', 'Dark dragon', 'Red ogre', 'Storm giant', 'Fire yai', 'Sword', 'Fireball']\n",
      "Topic 'dragon': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Red ogre', 'Storm giant', 'Cloud giant', 'Moon giant', 'Flaming sword', 'Sword', 'Rusting sword', 'Molten sword', 'Giant axe', 'Ocean devil', 'Infernal devil']\n",
      "Topic 'Orange': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Dark dragon', 'Black ogre', 'Red ogre', 'Orange ogre', 'Blue ogre']\n",
      "\n",
      "Finished. Remaining words were: [Halberd, Shadowball]\n"
     ]
    }
   ],
   "source": [
    "match_threshold = 100\n",
    "\n",
    "# With our model, assign each word to a linear combination of topics\n",
    "word_topics = model.transform(wv_matrix)\n",
    "y = np.argmax(word_topics, axis=1)\n",
    "\n",
    "threshold = match_threshold/num_components\n",
    "all_words = []\n",
    "\n",
    "# Iterate through each topic and get the words that are most associated with it, above a certain threshold\n",
    "for k in range(num_components):\n",
    "    words = []\n",
    "    for i in range(len(sample_words)):\n",
    "        if word_topics[i,k] > threshold:\n",
    "            words.append(sample_words[i].text)\n",
    "            all_words.append(sample_words[i].text)\n",
    "    \n",
    "    print(f\"Topic '%s': %s\" % (key_words_rounded[k], words))\n",
    "\n",
    "remaining_words = [x for x in sample_words if x.text not in all_words]\n",
    "print(f\"\\nFinished. Remaining words were: {remaining_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e8e0fd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 'Red': ['Red dragon', 'Blue dragon', 'Black ogre', 'Red ogre', 'Blue ogre']\n",
      "Topic 'Halberd': ['Sword', 'Molten sword', 'Halberd']\n",
      "Topic 'night': ['night']\n",
      "Topic 'Storm': ['Storm giant', 'Fireball']\n",
      "Topic 'bolt': ['Lightning bolt']\n",
      "Topic 'Fire': ['Water yai', 'Fire yai', 'Fireball']\n",
      "Topic 'Gold': ['Gold dragon', 'Silver dragon']\n",
      "Topic 'EnOcean': ['Ocean devil']\n",
      "Topic 'sword': ['Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Flaming sword', 'Sword', 'Rusting sword', 'Molten sword', 'Halberd', 'Giant axe', 'Infernal devil']\n",
      "Topic 'axe': ['Flaming sword', 'Rusting sword', 'Molten sword', 'Giant axe']\n",
      "Topic 'arch': ['Flaming arch']\n",
      "Topic 'Cloud': ['Cloud giant']\n",
      "Topic 'Sword': ['Blue dragon', 'Gold dragon', 'Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Flaming sword', 'Sword', 'Rusting sword', 'Molten sword', 'Halberd', 'Giant axe']\n",
      "Topic 'Moon': ['Blue dragon', 'Shadow dragon', 'Dark dragon', 'Blue ogre', 'Moon giant']\n",
      "Topic 'Dark': ['Red dragon', 'Blue dragon', 'Silver dragon', 'Shadow dragon', 'Dark dragon', 'Black ogre', 'Blue ogre', 'Sword']\n",
      "Topic 'Parectopa': []\n",
      "Topic 'Black': ['Red dragon', 'Blue dragon', 'Black ogre', 'Red ogre', 'Blue ogre']\n",
      "Topic 'Fireball': ['Blue dragon', 'Shadow dragon', 'Storm giant', 'Fire yai', 'Fireball']\n",
      "Topic 'dragon': ['Red dragon', 'Blue dragon', 'Gold dragon', 'Silver dragon', 'Magma dragon', 'Shadow dragon', 'Dark dragon', 'Moon giant', 'Flaming sword', 'Sword', 'Rusting sword', 'Molten sword', 'Giant axe', 'Infernal devil']\n",
      "Topic 'Orange': ['Orange ogre']\n",
      "\n",
      "Finished. Remaining words were: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/k8nz8_q571734_td8gl8pqbr0000gn/T/ipykernel_71927/2930584959.py:13: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similarity = nlp_word.similarity(nlp_key_word)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.45\n",
    "\n",
    "# With our model, assign each word to a linear combination of topics\n",
    "nlp_key_words = [nlp(x) for x in key_words_rounded]\n",
    "nlp_sample_words = [nlp(x.text) for x in sample_words]\n",
    "\n",
    "# Iterate through each topic and get the words that are most associated with it, above a certain threshold\n",
    "for k in range(num_components):\n",
    "    words = []\n",
    "    for i in range(len(sample_words)):\n",
    "        nlp_word = nlp_sample_words[i]\n",
    "        nlp_key_word = nlp_key_words[k]\n",
    "        similarity = nlp_word.similarity(nlp_key_word)\n",
    "        if similarity > threshold:\n",
    "            words.append(sample_words[i].text)\n",
    "            all_words.append(sample_words[i].text)\n",
    "    \n",
    "    print(f\"Topic '%s': %s\" % (key_words_rounded[k], words))\n",
    "\n",
    "remaining_words = [x for x in sample_words if x.text not in all_words]\n",
    "print(f\"\\nFinished. Remaining words were: {remaining_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90d31a",
   "metadata": {},
   "source": [
    "This is a vastly improved result (now we can assign a snippet to multiple groups).\n",
    "\n",
    "Issues:\n",
    "\n",
    "- Unrelated words are included such asin some iterations, or \n",
    "\n",
    "- Antonyms are included: 'blue ogre' might be included under 'Black'. This is because of the color commonality.\n",
    "\n",
    "- Unexpected commonalities are found. For example, for the pair *'Ocean devil'* and *'Infernal devil'* we get `EnOcean` instead of `devil`, We also get unrelated words such as  \"*teavee*\" (from Mike Teavee of Charlie and the Chocolate Factory) or *Parectopa*.\n",
    "    - This is likely because decomposition methods favour re-aggregation of the whole. While *teavee* seems useless, the vector probably allows reconsitution of some minor parts of the other words rather than be another useful 'subcluster' of another cluster. (TODO: Rephrase).\n",
    "    - Not only does this result in odd commonalities, but we can also be sure it is *missing* a lot of useful commonalities.\n",
    "- We find some unexpected sortings:\n",
    "    - For example: *lightning bolt* is not in `Storm`, but *fireball* is.\n",
    "\n",
    "Continuation:\n",
    "\n",
    "- What if we used our fantastical context for simlarity? For example, `sword` and `dragon` are rather different in our context, but because they are both used in fantasy, they are similar. We can try this in several ways:\n",
    "    - We can try *removing* the word vector for 'fantasy' as a part of preprocessing for all words.\n",
    "    - We can restructure 'similarity' to be 'similarity as a factor of its simlarity to fantasy'. So `similarity(sword and dragon) / similarity (fantasy)` (or perhaps `log(exp(x) + exp(y)` of same))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4ad20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
